{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28983424"
      },
      "source": [
        "## 1. Installation and Exploring Features of NLTK Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a577b1fa",
        "outputId": "3717ed29-1417-4cef-81d0-ac702e81d6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4df4f4f5",
        "outputId": "963ac2b3-5422-4d30-e9d2-7dbf84101a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d28a2292"
      },
      "source": [
        "## 2. Word, Sentence, and Paragraph Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b3e7df7",
        "outputId": "d08fba41-478c-44f4-9516-5416327a3d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', '.', 'It', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.', 'This', 'involves', 'understanding', ',', 'interpreting', ',', 'and', 'generating', 'human', 'language', '.']\n",
            "\n",
            "Sentence Tokens: ['\\nNatural Language Processing (NLP) is a field of computer science.', 'It focuses on the interaction between computers and human language.', 'This involves understanding, interpreting, and generating human language.']\n",
            "\n",
            "Paragraph Tokens: ['', 'Natural Language Processing (NLP) is a field of computer science. ', 'It focuses on the interaction between computers and human language.', 'This involves understanding, interpreting, and generating human language.', '']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of computer science.\n",
        "It focuses on the interaction between computers and human language.\n",
        "This involves understanding, interpreting, and generating human language.\n",
        "\"\"\"\n",
        "\n",
        "word_tokens = word_tokenize(text)\n",
        "sentence_tokens = sent_tokenize(text)\n",
        "paragraph_tokens = text.split(\"\\n\")\n",
        "\n",
        "print(\"Word Tokens:\", word_tokens)\n",
        "print(\"\\nSentence Tokens:\", sentence_tokens)\n",
        "print(\"\\nParagraph Tokens:\", paragraph_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb8b0435"
      },
      "source": [
        "## 3. Corpus Word Count and Distinct Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14b4601b",
        "outputId": "66702844-ad88-4bde-c7af-14ff1b4955bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in corpus: 192427\n",
            "Distinct words: 7811\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "words = gutenberg.words(\"austen-emma.txt\")\n",
        "print(\"Total words in corpus:\", len(words))\n",
        "print(\"Distinct words:\", len(set(words)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e8faa91"
      },
      "source": [
        "## 4. Removing Stop Words from Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f8fa3c8",
        "outputId": "a1f4a23c-ff66-478e-b0e1-9554974b69ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Words (without stopwords): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'field', 'computer', 'science', '.', 'focuses', 'interaction', 'computers', 'human', 'language', '.', 'involves', 'understanding', ',', 'interpreting', ',', 'generating', 'human', 'language', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "print(\"Filtered Words (without stopwords):\", filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93efcf3c"
      },
      "source": [
        "## 5. Top 10 Frequent Words (Excluding Stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef8c9020",
        "outputId": "acd03eb1-60e5-41c6-d91f-01a3a70ab430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('language', 3), ('human', 2), ('natural', 1), ('processing', 1), ('nlp', 1), ('field', 1), ('computer', 1), ('science', 1), ('focuses', 1), ('interaction', 1)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_frequent_non_stopwords(text, n=10):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    freq_dist = Counter(filtered)\n",
        "    return freq_dist.most_common(n)\n",
        "\n",
        "print(top_frequent_non_stopwords(text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}